{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/rabin1323/Artificial_Lab/blob/main/AI_ASO4.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports and pip installations (if needed)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> I have used a link to access iris dataset remotely. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sepal_length  sepal_width  petal_length  petal_width        Class\n",
      "0            5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1            4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2            4.7          3.2           1.3          0.2  Iris-setosa\n",
      "3            4.6          3.1           1.5          0.2  Iris-setosa\n",
      "4            5.0          3.6           1.4          0.2  Iris-setosa\n",
      "5            5.4          3.9           1.7          0.4  Iris-setosa\n",
      "6            4.6          3.4           1.4          0.3  Iris-setosa\n",
      "7            5.0          3.4           1.5          0.2  Iris-setosa\n",
      "8            4.4          2.9           1.4          0.2  Iris-setosa\n",
      "9            4.9          3.1           1.5          0.1  Iris-setosa\n",
      "10           5.4          3.7           1.5          0.2  Iris-setosa\n",
      "11           4.8          3.4           1.6          0.2  Iris-setosa\n",
      "12           4.8          3.0           1.4          0.1  Iris-setosa\n",
      "13           4.3          3.0           1.1          0.1  Iris-setosa\n",
      "14           5.8          4.0           1.2          0.2  Iris-setosa\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      "sepal_length    150 non-null float64\n",
      "sepal_width     150 non-null float64\n",
      "petal_length    150 non-null float64\n",
      "petal_width     150 non-null float64\n",
      "Class           150 non-null object\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#Load the dataset (load remotely, not locally)\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header = None)\n",
    "data.columns = ['sepal_length','sepal_width','petal_length','petal_width','Class']\n",
    "#data load_iris()\n",
    "#Output the first 15 rows of the data\n",
    "print(data.head(15))\n",
    "#Display a summary of the table information (number of datapoints, etc.)\n",
    "#data.describe()\n",
    "data.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfroming the string to numeric for Better Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal_length  sepal_width  petal_length  petal_width  Class\n",
       "0            5.1          3.5           1.4          0.2      0\n",
       "1            4.9          3.0           1.4          0.2      0\n",
       "2            4.7          3.2           1.3          0.2      0\n",
       "3            4.6          3.1           1.5          0.2      0\n",
       "4            5.0          3.6           1.4          0.2      0\n",
       "5            5.4          3.9           1.7          0.4      0\n",
       "6            4.6          3.4           1.4          0.3      0\n",
       "7            5.0          3.4           1.5          0.2      0\n",
       "8            4.4          2.9           1.4          0.2      0\n",
       "9            4.9          3.1           1.5          0.1      0\n",
       "10           5.4          3.7           1.5          0.2      0\n",
       "11           4.8          3.4           1.6          0.2      0\n",
       "12           4.8          3.0           1.4          0.1      0\n",
       "13           4.3          3.0           1.1          0.1      0\n",
       "14           5.8          4.0           1.2          0.2      0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "data['Class'] = le.fit_transform(data['Class'])\n",
    "data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the dataset\n",
    "### Explain what the data is in your own words. What are your features and labels? What is the mapping of your labels to the actual classes?\n",
    "\n",
    "<p> The iris dataset is about different iris flowers belongig to three different species or class. The three different speceis are iris-setosa', 'iris-versicolor', and'iris-virginica. The data has four other features which are: 'SepalLength', 'SepalWidth', 'PetalLength' and 'Petal Width'. All the lengths are in centimeter. The species from the dataset is string so, to do analysis I have change transform that to numeric. After transfoming to numeric 'Setosa maps to 0' , 'Versicolor maps to 1' and 'Verginica maps to 2'.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Split the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the dataset and split it into our features (X) and label (y)\n",
    "x = data[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "y = data['Class']\n",
    "# Use sklearn to split the features and labels into a training/test set. (90% train, 10% test)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part 3: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proabability :[[8.86074724e-01 1.13914344e-01 1.09316663e-05]\n",
      " [8.14768212e-01 1.85162296e-01 6.94921641e-05]\n",
      " [6.91272578e-04 1.39547438e-01 8.59761290e-01]\n",
      " [8.82009237e-01 1.17981564e-01 9.19914647e-06]\n",
      " [3.36548768e-02 8.07124248e-01 1.59220875e-01]\n",
      " [8.74260882e-01 1.25678797e-01 6.03209742e-05]\n",
      " [7.87609409e-01 2.12354120e-01 3.64717825e-05]\n",
      " [1.26403125e-03 3.26784243e-01 6.71951726e-01]\n",
      " [2.13530318e-04 2.72463807e-01 7.27322663e-01]\n",
      " [5.04206260e-04 4.32228917e-01 5.67266877e-01]\n",
      " [1.99435208e-04 3.66422037e-01 6.33378528e-01]\n",
      " [2.26159266e-03 5.18782819e-01 4.78955588e-01]\n",
      " [1.29297690e-02 4.44087133e-01 5.42983098e-01]\n",
      " [1.38892467e-02 6.58302724e-01 3.27808029e-01]\n",
      " [7.11385297e-04 4.01943518e-01 5.97345097e-01]]\n",
      "Score :0.8666666666666667\n",
      "Coefficient : [[ 0.39791046  1.43829909 -2.21887232 -1.01141246]\n",
      " [ 0.46254725 -1.54375384  0.58343652 -1.41425681]\n",
      " [-1.67356563 -1.48299489  2.30507136  2.59480736]]\n",
      "Intercept : [ 0.26009898  0.73659076 -0.93795511]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#i. Use sklearn to train a LogisticRegression model on the training set\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "#ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "print(f\"Proabability :{model.predict_proba(x_test)}\")\n",
    "#iii. Report on the score for Logistic regression model, what does the score measure?\n",
    "'''The score in logistic regression is the mean accuracy on the given test data and labels.'''\n",
    "print(f\"Score :{model.score(x_test,y_test)}\")\n",
    "#iv. Extract the coefficents and intercepts for the boundary line(s)\n",
    "print(f\"Coefficient : {model.coef_}\")\n",
    "print(f\"Intercept : {model.intercept_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability: [[0.96578776 0.01870578 0.01550646]\n",
      " [0.96440296 0.01971696 0.01588008]\n",
      " [0.01342967 0.0051496  0.98142072]\n",
      " [0.96410867 0.02002811 0.01586322]\n",
      " [0.00768192 0.98771846 0.00459962]\n",
      " [0.96155798 0.02287226 0.01556976]\n",
      " [0.96453301 0.01938836 0.01607863]\n",
      " [0.01081261 0.02697247 0.96221492]\n",
      " [0.03044217 0.03699404 0.93256379]\n",
      " [0.01234211 0.01904094 0.96861696]\n",
      " [0.01329167 0.01471293 0.9719954 ]\n",
      " [0.0129623  0.46002835 0.52700935]\n",
      " [0.00893459 0.91122875 0.07983666]\n",
      " [0.00643269 0.97105651 0.0225108 ]\n",
      " [0.03316007 0.05410245 0.91273748]]\n",
      "Score :1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# i. Use sklearn to train a Support Vector Classifier on the training set\n",
    "svm_model = SVC(probability=True)\n",
    "svm_model.fit(x_train,y_train)\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "print(f\"Probability: {svm_model.predict_proba(x_test)}\")\n",
    "# iii. Report on the score for the SVM, what does the score measure?\n",
    "'''The Score in Support Vector Machine is the mean accuracy on the given test data and labels'''\n",
    "print(f\"Score :{svm_model.score(x_test,y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability: [[9.84822012e-01 1.51716687e-02 6.31974252e-06]\n",
      " [9.54578625e-01 4.53634240e-02 5.79507109e-05]\n",
      " [5.68596708e-04 7.86959336e-02 9.20735470e-01]\n",
      " [9.84454221e-01 1.55399146e-02 5.86397314e-06]\n",
      " [1.84090599e-02 8.71500985e-01 1.10089955e-01]\n",
      " [9.64213072e-01 3.57464473e-02 4.04807102e-05]\n",
      " [9.62181533e-01 3.77855600e-02 3.29068460e-05]\n",
      " [1.51787711e-03 2.99975874e-01 6.98506249e-01]\n",
      " [3.01303891e-04 1.38866561e-01 8.60832135e-01]\n",
      " [9.07995578e-04 3.02737855e-01 6.96354149e-01]\n",
      " [2.25735708e-04 1.52518599e-01 8.47255665e-01]\n",
      " [3.72296536e-03 4.96241422e-01 5.00035613e-01]\n",
      " [1.43798069e-02 6.03268013e-01 3.82352181e-01]\n",
      " [1.36261843e-02 7.25244350e-01 2.61129466e-01]\n",
      " [1.08903317e-03 3.87056370e-01 6.11854597e-01]]\n",
      "Score :1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The best configuration is above and with that configuration I have obtain 100% Score. While working with the configuration I found that when the \\nhidden layer units are >100 and max_iter value is high, the score is high.'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i. Use sklearn to train a Neural Network (MLP Classifier) on the training set\n",
    "clf = MLPClassifier(random_state=1,hidden_layer_sizes=(100), max_iter=300)\n",
    "clf.fit(x_train, y_train)\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "print(f\"Probability: {clf.predict_proba(x_test)}\")\n",
    "# iii. Report on the score for the Neural Network, what does the score measure?\n",
    "'''The Score for the Neureal Network Measures the mean accuracy on the given test data and labels'''\n",
    "print(f\"Score :{clf.score(x_test,y_test)}\")\n",
    "# iv: Experiment with different options for the neural network, report on your best configuration (the highest score I was able to achieve was 0.8666)\n",
    "'''The best configuration is above and with that configuration I have obtain 100% Score. While working with the configuration I found that when the \n",
    "hidden layer units are >100 and max_iter value is high, the score is high.'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability: [[1.  0.  0. ]\n",
      " [1.  0.  0. ]\n",
      " [0.  0.  1. ]\n",
      " [1.  0.  0. ]\n",
      " [0.  1.  0. ]\n",
      " [1.  0.  0. ]\n",
      " [1.  0.  0. ]\n",
      " [0.  0.  1. ]\n",
      " [0.  0.  1. ]\n",
      " [0.  0.  1. ]\n",
      " [0.  0.  1. ]\n",
      " [0.  0.4 0.6]\n",
      " [0.  1.  0. ]\n",
      " [0.  1.  0. ]\n",
      " [0.  0.  1. ]]\n",
      "Score :1.0\n"
     ]
    }
   ],
   "source": [
    "# i. Use sklearn to 'train' a k-Neighbors Classifier\n",
    "# Note: KNN is a nonparametric model and technically doesn't require training\n",
    "# fit will essentially load the data into the model see link below for more information\n",
    "# https://stats.stackexchange.com/questions/349842/why-do-we-need-to-fit-a-k-nearest-neighbors-classifier\n",
    "kmodel = KNeighborsClassifier(n_neighbors=5)\n",
    "kmodel.fit(x_train,y_train)\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "print(f\"Probability: {kmodel.predict_proba(x_test)}\")\n",
    "# iii. Report on the score for kNN, what does the score measure?\n",
    "'''THE Score for KNN Measures the mean accuracy on the given test data and labels'''\n",
    "print(f\"Score :{kmodel.score(x_test,y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Conclusions and takeaways\n",
    "<p>In your own words describe the results of the notebook. Which model(s) performed the best on the dataset? Why do you think that is? Did anything surprise you about the exercise?</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>After training and testing the irish data, I found that all three models except logistic regression are performing really well. Looking at the probability predicted by KNN, I was able to see very clear data. Some of the probability were 0 while some of the probability were 1 for KNN models. What surprise me in this notebook is unlike linear regression all the models score measures the mean accuracy on the test data and labels. Where as in Linear regression, The score give the coefficient of determination of the prediction</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
